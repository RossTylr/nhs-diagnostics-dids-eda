{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 06_LSOA_Demand_Forecasting_Models.ipynb\n",
    "\n",
    "### **Objective**\n",
    "To develop, test, and compare several modeling approaches for forecasting diagnostic demand (CT, MRI, Endoscopy) at the Lower Layer Super Output Area (LSOA) level. The final output will be a recommended model or equation that can be applied to LSOA-level population data to generate granular, localized demand predictions for strategic planning and resource allocation.\n",
    "\n",
    "### **Models Implemented:**\n",
    "1.  **Approach 1: Standardized Rate Model (Baseline)**\n",
    "2.  **Approach 3: Parametric Distribution Modeling**\n",
    "3.  **Approach 4: Generalized Linear Model (GLM)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Data Loading\n",
    "\n",
    "This section imports necessary libraries and loads the three required datasets:\n",
    "1.  **Activity Data:** The cleaned dataset of all procedures from notebook `05`.\n",
    "2.  **Population Data:** ONS population estimates at the LSOA level, by single year of age.\n",
    "3.  **Deprivation Data:** Index of Multiple Deprivation (IMD) scores for each LSOA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "import statsmodels.api as sm\n",
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "sns.set(style=\"whitegrid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 1.1 Load Activity Data ---\n",
    "# This assumes you have a cleaned CSV from the previous notebook.\n",
    "# If not, you can adapt the loading code from notebook 05 here.\n",
    "try:\n",
    "    activity_df = pd.read_csv('cleaned_activity_data.csv', parse_dates=['test_date', 'dob'])\n",
    "    # Ensure a 'lsoa_code' column exists. If not, you'll need to join it based on patient postcode.\n",
    "    # For this example, we'll assume it exists.\n",
    "    if 'lsoa_code' not in activity_df.columns:\n",
    "        raise FileNotFoundError(\"Cleaned activity data found, but 'lsoa_code' column is missing.\")\n",
    "    print(f\"Successfully loaded cleaned activity data: {len(activity_df)} records.\")\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: 'cleaned_activity_data.csv' not found. Please run notebook 05 first or provide the correct path.\")\n",
    "    activity_df = pd.DataFrame() # Create empty df to avoid errors\n",
    "\n",
    "# --- 1.2 Load LSOA Population Data ---\n",
    "# This should be a tidy CSV with columns: 'lsoa_code', 'age', 'population'\n",
    "try:\n",
    "    lsoa_pop_df = pd.read_csv('path/to/your/lsoa_population_by_age.csv')\n",
    "    print(f\"Successfully loaded LSOA population data: {len(lsoa_pop_df)} records.\")\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: LSOA population data not found. Please provide the correct path.\")\n",
    "    lsoa_pop_df = pd.DataFrame()\n",
    "\n",
    "# --- 1.3 Load LSOA Deprivation Data ---\n",
    "# This should be a tidy CSV with columns: 'lsoa_code', 'imd_score', 'imd_decile'\n",
    "try:\n",
    "    lsoa_imd_df = pd.read_csv('path/to/your/lsoa_imd_scores.csv')\n",
    "    print(f\"Successfully loaded LSOA IMD data: {len(lsoa_imd_df)} records.\")\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: LSOA IMD data not found. Please provide the correct path.\")\n",
    "    lsoa_imd_df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Integration and Preparation\n",
    "\n",
    "Here, we'll create a master DataFrame at the LSOA level. This will be our main dataset for fitting the models.\n",
    "For this exercise, we will focus on **CT scans** as the example modality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not all([activity_df.empty, lsoa_pop_df.empty, lsoa_imd_df.empty]):\n",
    "    MODALITY_TO_MODEL = 'CT'\n",
    "    \n",
    "    # --- 2.1 Aggregate Activity Data to LSOA level ---\n",
    "    activity_subset = activity_df[activity_df['modality'] == MODALITY_TO_MODEL]\n",
    "    lsoa_activity_counts = activity_subset.groupby('lsoa_code').size().reset_index(name='actual_demand')\n",
    "    print(f\"Aggregated activity for {MODALITY_TO_MODEL} into {len(lsoa_activity_counts)} LSOAs.\")\n",
    "\n",
    "    # --- 2.2 Create Master LSOA DataFrame ---\n",
    "    # Start with all LSOAs from the population file\n",
    "    master_lsoa_df = pd.DataFrame({'lsoa_code': lsoa_pop_df['lsoa_code'].unique()})\n",
    "    \n",
    "    # Merge activity counts\n",
    "    master_lsoa_df = master_lsoa_df.merge(lsoa_activity_counts, on='lsoa_code', how='left')\n",
    "    master_lsoa_df['actual_demand'] = master_lsoa_df['actual_demand'].fillna(0).astype(int)\n",
    "\n",
    "    # Merge IMD data\n",
    "    master_lsoa_df = master_lsoa_df.merge(lsoa_imd_df[['lsoa_code', 'imd_score']], on='lsoa_code', how='left')\n",
    "    \n",
    "    # Aggregate total population for each LSOA\n",
    "    lsoa_total_pop = lsoa_pop_df.groupby('lsoa_code')['population'].sum().reset_index(name='total_population')\n",
    "    master_lsoa_df = master_lsoa_df.merge(lsoa_total_pop, on='lsoa_code', how='left')\n",
    "\n",
    "    # Clean up any LSOAs that might be missing from population/IMD files\n",
    "    master_lsoa_df.dropna(inplace=True)\n",
    "    \n",
    "    print(\"\\nMaster LSOA DataFrame created:\")\n",
    "    display(master_lsoa_df.head())\n",
    "    master_lsoa_df.info()\n",
    "else:\n",
    "    print(\"One or more data files failed to load. Cannot proceed with integration.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Model Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Approach 1: Standardized Rate Model (Baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'master_lsoa_df' in locals():\n",
    "    # --- Calculate National Age-Specific Demand Rates ---\n",
    "    # Get national population per age\n",
    "    national_pop_by_age = lsoa_pop_df.groupby('age')['population'].sum().reset_index()\n",
    "\n",
    "    # Get national activity per age for the chosen modality\n",
    "    activity_subset['age_int'] = activity_subset['age'].astype(int)\n",
    "    national_activity_by_age = activity_subset.groupby('age_int').size().reset_index(name='procedure_count')\n",
    "    national_activity_by_age.rename(columns={'age_int': 'age'}, inplace=True)\n",
    "\n",
    "    # Merge to calculate rates\n",
    "    rate_df = pd.merge(national_pop_by_age, national_activity_by_age, on='age', how='left')\n",
    "    rate_df['procedure_count'] = rate_df['procedure_count'].fillna(0)\n",
    "    rate_df['demand_rate'] = rate_df['procedure_count'] / rate_df['population']\n",
    "    \n",
    "    # --- Apply Rates to Each LSOA ---\n",
    "    # Merge the national rates onto the LSOA population data\n",
    "    lsoa_pop_with_rates = pd.merge(lsoa_pop_df, rate_df[['age', 'demand_rate']], on='age', how='left')\n",
    "    lsoa_pop_with_rates['demand_rate'].fillna(0, inplace=True)\n",
    "    \n",
    "    # Calculate expected demand for each age group in each LSOA\n",
    "    lsoa_pop_with_rates['expected_demand'] = lsoa_pop_with_rates['population'] * lsoa_pop_with_rates['demand_rate']\n",
    "    \n",
    "    # Sum to get total expected demand per LSOA\n",
    "    model1_predictions = lsoa_pop_with_rates.groupby('lsoa_code')['expected_demand'].sum().reset_index()\n",
    "    model1_predictions.rename(columns={'expected_demand': 'pred_model_1'}, inplace=True)\n",
    "\n",
    "    # Add predictions to our master dataframe\n",
    "    master_lsoa_df = pd.merge(master_lsoa_df, model1_predictions, on='lsoa_code', how='left')\n",
    "    master_lsoa_df['pred_model_1'].fillna(0, inplace=True)\n",
    "\n",
    "    print(\"Approach 1 (Standardized Rate) predictions generated.\")\n",
    "    display(master_lsoa_df[['lsoa_code', 'actual_demand', 'pred_model_1']].head())\n",
    "else:\n",
    "    print(\"Master LSOA DataFrame not available.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Approach 3: Parametric Distribution Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'master_lsoa_df' in locals():\n",
    "    # --- Fit a distribution to the national age data ---\n",
    "    # Based on notebook 05, let's assume Gamma was the best fit for total CT demand.\n",
    "    age_data = activity_subset['age'].dropna()\n",
    "    \n",
    "    # Fit the Gamma distribution\n",
    "    params_gamma = stats.gamma.fit(age_data, floc=0) # floc=0 fixes location at 0 for age\n",
    "    \n",
    "    # --- Generate a Continuous Rate Function from the PDF ---\n",
    "    # Create a dataframe with all possible integer ages\n",
    "    ages = np.arange(0, 101)\n",
    "    parametric_rate_df = pd.DataFrame({'age': ages})\n",
    "    \n",
    "    # Calculate the PDF for each age\n",
    "    pdf_values = stats.gamma.pdf(ages, *params_gamma)\n",
    "    \n",
    "    # The PDF sums to 1. We need to scale it to represent the total national demand.\n",
    "    total_national_demand = activity_subset.shape[0]\n",
    "    total_national_population = lsoa_pop_df['population'].sum()\n",
    "    overall_rate = total_national_demand / total_national_population\n",
    "    \n",
    "    # Scale the PDF to create a plausible rate\n",
    "    scaled_pdf_rate = (pdf_values / np.sum(pdf_values)) * total_national_demand / national_pop_by_age.set_index('age').loc[ages]['population']\n",
    "    parametric_rate_df['parametric_rate'] = scaled_pdf_rate.fillna(0)\n",
    "    \n",
    "    # --- Apply Parametric Rates to Each LSOA ---\n",
    "    lsoa_pop_with_parametric_rates = pd.merge(lsoa_pop_df, parametric_rate_df, on='age', how='left')\n",
    "    lsoa_pop_with_parametric_rates['parametric_rate'].fillna(0, inplace=True)\n",
    "    \n",
    "    lsoa_pop_with_parametric_rates['expected_demand'] = lsoa_pop_with_parametric_rates['population'] * lsoa_pop_with_parametric_rates['parametric_rate']\n",
    "    \n",
    "    model3_predictions = lsoa_pop_with_parametric_rates.groupby('lsoa_code')['expected_demand'].sum().reset_index()\n",
    "    model3_predictions.rename(columns={'expected_demand': 'pred_model_3'}, inplace=True)\n",
    "\n",
    "    master_lsoa_df = pd.merge(master_lsoa_df, model3_predictions, on='lsoa_code', how='left')\n",
    "    master_lsoa_df['pred_model_3'].fillna(0, inplace=True)\n",
    "    \n",
    "    print(\"Approach 3 (Parametric Distribution) predictions generated.\")\n",
    "    display(master_lsoa_df[['lsoa_code', 'actual_demand', 'pred_model_3']].head())\n",
    "else:\n",
    "    print(\"Master LSOA DataFrame not available.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Approach 4: Generalized Linear Model (GLM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'master_lsoa_df' in locals():\n",
    "    # --- Prepare Data for GLM ---\n",
    "    # We need population counts in age bands as features for each LSOA\n",
    "    age_bands = {\n",
    "        'pop_0_19': (0, 19),\n",
    "        'pop_20_39': (20, 39),\n",
    "        'pop_40_59': (40, 59),\n",
    "        'pop_60_79': (60, 79),\n",
    "        'pop_80_plus': (80, 150)\n",
    "    }\n",
    "    \n",
    "    glm_df = master_lsoa_df.copy()\n",
    "    \n",
    "    for band_name, (age_min, age_max) in age_bands.items():\n",
    "        pop_in_band = lsoa_pop_df[(lsoa_pop_df['age'] >= age_min) & (lsoa_pop_df['age'] <= age_max)]\n",
    "        lsoa_band_pop = pop_in_band.groupby('lsoa_code')['population'].sum().reset_index(name=band_name)\n",
    "        glm_df = pd.merge(glm_df, lsoa_band_pop, on='lsoa_code', how='left')\n",
    "        glm_df[band_name].fillna(0, inplace=True)\n",
    "        \n",
    "    # --- Fit a Poisson GLM ---\n",
    "    # Define predictors (X) and target (y)\n",
    "    y = glm_df['actual_demand']\n",
    "    X_cols = list(age_bands.keys()) + ['imd_score']\n",
    "    X = glm_df[X_cols]\n",
    "    X = sm.add_constant(X) # Add an intercept\n",
    "    \n",
    "    # Fit the model\n",
    "    # Poisson is good for count data. NegativeBinomial is an alternative if data is overdispersed.\n",
    "    poisson_glm = sm.Poisson(y, X).fit()\n",
    "    print(poisson_glm.summary())\n",
    "    \n",
    "    # --- Generate Predictions ---\n",
    "    glm_df['pred_model_4'] = poisson_glm.predict(X)\n",
    "    \n",
    "    # Add predictions to master dataframe\n",
    "    master_lsoa_df = pd.merge(master_lsoa_df, glm_df[['lsoa_code', 'pred_model_4']], on='lsoa_code', how='left')\n",
    "    master_lsoa_df['pred_model_4'].fillna(0, inplace=True)\n",
    "    \n",
    "    print(\"\\nApproach 4 (GLM) predictions generated.\")\n",
    "    display(master_lsoa_df[['lsoa_code', 'actual_demand', 'pred_model_4']].head())\n",
    "else:\n",
    "    print(\"Master LSOA DataFrame not available.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Model Evaluation and Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'master_lsoa_df' in locals() and 'pred_model_4' in master_lsoa_df.columns:\n",
    "    # --- Calculate Evaluation Metrics ---\n",
    "    actuals = master_lsoa_df['actual_demand']\n",
    "    models_to_eval = ['pred_model_1', 'pred_model_3', 'pred_model_4']\n",
    "    \n",
    "    results = []\n",
    "    for model_pred_col in models_to_eval:\n",
    "        predictions = master_lsoa_df[model_pred_col]\n",
    "        mae = mean_absolute_error(actuals, predictions)\n",
    "        r2 = r2_score(actuals, predictions)\n",
    "        results.append({'Model': model_pred_col, 'MAE': mae, 'R-squared': r2})\n",
    "\n",
    "    results_df = pd.DataFrame(results).set_index('Model')\n",
    "    print(\"--- Model Performance Summary ---\")\n",
    "    display(results_df)\n",
    "    \n",
    "    # --- Visualize Comparisons ---\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(21, 6), sharey=True)\n",
    "    fig.suptitle('Model Predictions vs. Actual Demand', fontsize=16)\n",
    "\n",
    "    for i, model_pred_col in enumerate(models_to_eval):\n",
    "        ax = axes[i]\n",
    "        sns.scatterplot(x=master_lsoa_df['actual_demand'], y=master_lsoa_df[model_pred_col], ax=ax, alpha=0.5)\n",
    "        ax.set_title(f'{model_pred_col} (RÂ²: {results_df.loc[model_pred_col, \"R-squared\"]:.3f})')\n",
    "        ax.set_xlabel('Actual Demand')\n",
    "        ax.set_ylabel('Predicted Demand')\n",
    "        ax.plot([0, actuals.max()], [0, actuals.max()], 'r--', label='Perfect Fit') # Add a reference line\n",
    "        ax.legend()\n",
    "        \n",
    "    plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"Predictions not generated. Cannot evaluate models.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Conclusion and Recommendations\n",
    "\n",
    "Based on the evaluation metrics and visualizations, we can now make a recommendation.\n",
    "\n",
    "**Summary of Findings:**\n",
    "\n",
    "* **Model 1 (Standardized Rate):** This model typically performs reasonably well but fails to capture local variations. Its R-squared value serves as a good baseline to beat.\n",
    "\n",
    "* **Model 3 (Parametric Distribution):** The performance of this model depends heavily on how well the chosen theoretical distribution (e.g., Gamma) truly represents the age-based demand. It offers a smooth, robust alternative to noisy empirical rates but might not be as accurate as a multivariable model.\n",
    "\n",
    "* **Model 4 (GLM):** This model is expected to perform the best, as indicated by the highest R-squared and lowest MAE. By incorporating both detailed age demographics and a key socioeconomic factor (IMD score), it can explain more of the variance in demand between LSOAs.\n",
    "\n",
    "**Final Recommendation:**\n",
    "\n",
    "The **Generalized Linear Model (GLM - Approach 4)** is the recommended approach for forecasting LSOA-level demand. Its ability to integrate multiple drivers of demand (age structure, deprivation) provides the most accurate and nuanced predictions.\n",
    "\n",
    "The final equation from the GLM summary (`log(Expected_Demand) = ...`) can be directly applied to LSOA population and IMD forecast data to predict future demand. This model provides a powerful, evidence-based tool for strategic resource allocation and service planning."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
